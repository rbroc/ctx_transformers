{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9133,"status":"ok","timestamp":1613118465322,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"_1yVf0JAHIfQ","outputId":"6e456f28-8e76-4d08-d8d5-f0d2f1e2804e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 6.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 31.2MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 40.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=6deea9a9d659726aeb5effc744ab1d570e30a52fcdd737fa88193d30bab72a83\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11963,"status":"ok","timestamp":1613118468174,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"Z_zi0jaEG_vR"},"outputs":[],"source":["from tensorflow import keras\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras import layers, Input\n","from transformers import TFDistilBertModel\n","import glob\n","from tensorflow.keras.utils import Progbar\n","from google.colab import drive\n","import os\n","from pathlib import Path\n","import json\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","import pickle as pkl\n","from reddit import load_tfrecord_triplet, split_dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86816,"status":"ok","timestamp":1613118543034,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"81GoGb-sCwOj","outputId":"e0bf9d91-acb7-4e54-ec5e-3af6ad390052"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n","/content/drive/My Drive/personality_reddit\n"]}],"source":["drive.mount('/content/drive/')\n","%cd 'drive/My Drive/personality_reddit'"]},{"cell_type":"markdown","metadata":{"id":"m7xIzA1Zborq"},"source":["## Initialize TPU strategy"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108556,"status":"ok","timestamp":1613118564788,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"dfdvPoLTHobI","outputId":"896bdc5a-1e07-40a7-abaa-3c1bcabff3be"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.109.133.186:8470\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.109.133.186:8470\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["Running on TPU  ['10.109.133.186:8470']\n","Number of accelerators:  8\n"]}],"source":["try:\n","  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n","  print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n","except ValueError:\n","  print('TPU failed to initialize.')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":108550,"status":"ok","timestamp":1613118564788,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"MpMvuoq6N2UY"},"outputs":[],"source":["AUTO = tf.data.experimental.AUTOTUNE"]},{"source":["## Define dataset parameters"],"cell_type":"markdown","metadata":{}},{"source":["batch_size = 1 # >1 not feasible on Colab TPUs\n","global_batch_size = batch_size * strategy.num_replicas_in_sync\n","n_posts = 50\n","samples_in_toy_dataset = 10000"],"cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IjLNbAa9G_vc"},"source":["## Load and distribute dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182552,"status":"ok","timestamp":1613118638803,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"h7K0T-bUN-su","outputId":"e74fc563-0fb3-4cd5-c79f-2e0749572798"},"outputs":[{"name":"stdout","output_type":"stream","text":["Updated property [core/project].\n"]}],"source":["from google.colab import auth\n","auth.authenticate_user()\n","!gcloud config set project thematic-cursor-254011"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":183839,"status":"ok","timestamp":1613118640097,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"EY_DK7PMDnmD"},"outputs":[],"source":["fre = 'gs://personality_reddit/triplet_nn1/*-of-999.tfrecord'\n","fnames = tf.io.gfile.glob(fre)"]},{"source":["ds = load_tfrecord_triplet_nn1(filenames=fnames, num_parallel_calls=AUTO)\n","ds = ds.map(lambda x: tf.reverse(x['input_ids'], [0])[:n_posts,:]) \\\n","       .prefetch(AUTO) \\\n","       .padded_batch(global_batch_size, \n","                     padded_shapes=[n_posts, None],\n","                     drop_remainder=True)"],"cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":184054,"status":"ok","timestamp":1613118640327,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"w0dfP625Hkoy"},"outputs":[],"source":["ds_tuning, ds_train, ds_val, ds_test = split_dataset(ds, tuning=10000)\n","ds_tuning, ds_val, ds_test = (strategy.experimental_distribute_dataset(d) for d in [ds_tuning, ds_val, ds_test])"]},{"cell_type":"markdown","metadata":{"id":"1S6L_ZwHNS1x"},"source":["## Define model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_ids = Input(shape=(None, 512), dtype='int32', name='input_ids')"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":184255,"status":"ok","timestamp":1613118640554,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"8RbNdsX5NMbK"},"outputs":[],"source":["class CustomBertLayer(keras.Model):\n","  def __init__(self, model, name=None, trainable=True):\n","    super(CustomBertLayer, self).__init__(name=name)\n","    self.model = model\n","    self.trainable = trainable\n","    self.output_signature = tf.float32\n","\n","  def call(self, input):\n","    def red_fn(x):\n","      enc = self.model(x).last_hidden_state[:,0,:]\n","      mask = tf.cast(tf.not_equal(tf.reduce_mean(x, axis=1), 0), \n","                     tf.float32)\n","      masked = tf.multiply(enc, tf.expand_dims(mask, 1))\n","      return masked\n","\n","    enc = tf.vectorized_map(lambda x: red_fn(x), elems=input)\n","    nonzero = tf.cast(tf.math.count_nonzero(tf.reduce_sum(input, axis=-1), axis=1), tf.float32)\n","    return enc, nonzero"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":184250,"status":"ok","timestamp":1613118640554,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"1YvNNfs-nJ5X"},"outputs":[],"source":["def triplet_loss(margin):\n","  def loss_fn(enc, nonzero):\n","\n","    # Get embeddings\n","    n_emb = enc[:,0,:]\n","    p_emb = enc[:,1,:]\n","    a_emb = enc[:,2:,:]\n","    \n","    # Compute average distance between anchor embeddings (ONLY WORKS for batch=1)\n","    r = tf.reduce_sum(a_emb[0,:,:] * a_emb[0,:,:], 1)\n","    mask = tf.abs(tf.cast(tf.equal(r,0), tf.float32) - 1.0)\n","    r = tf.reshape(r, [-1, 1])\n","    D = r - 2*tf.matmul(a_emb[0,:,:], \n","                        tf.transpose(a_emb[0,:,:])) + tf.transpose(r)\n","    D = tf.transpose(D * mask) * mask\n","    D = tf.linalg.band_part(D,-1,0) # lower triangle\n","    nr_comb = tf.reduce_sum(tf.cast(tf.range(1,n_posts-1), tf.float32) * mask)\n","    mdist = tf.divide(tf.reduce_sum(D), nr_comb)\n","\n","    # Compute distances\n","    a_emb = tf.divide(tf.reduce_sum(a_emb, axis=1), nonzero-2)\n","    d_pos = tf.reduce_sum(tf.square(a_emb - p_emb), 1)\n","    d_neg = tf.reduce_sum(tf.square(a_emb - n_emb), 1)\n","\n","    # Compute loss\n","    loss_val = tf.maximum(0.0, margin + (d_pos - d_neg) )\n","\n","    # Return\n","    loss_val = tf.reduce_mean(loss_val)\n","    d_pos = tf.reduce_mean(d_pos)\n","    d_neg = tf.reduce_mean(d_neg)\n","    \n","    return loss_val, d_pos, d_neg, mdist\n","  \n","  return loss_fn"]},{"cell_type":"markdown","metadata":{"id":"U9vU8AqjG_vd"},"source":["## Training protocol"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":196230,"status":"ok","timestamp":1613118652543,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"wmV8h3BtnQMv","outputId":"6fe4b68f-cbb8-4d01-fc87-cc15f4742da7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 849kB 6.4MB/s \n","\u001b[K     |████████████████████████████████| 706kB 17.3MB/s \n","\u001b[K     |████████████████████████████████| 1.2MB 25.6MB/s \n","\u001b[K     |████████████████████████████████| 37.6MB 1.4MB/s \n","\u001b[K     |████████████████████████████████| 174kB 50.4MB/s \n","\u001b[K     |████████████████████████████████| 358kB 47.8MB/s \n","\u001b[K     |████████████████████████████████| 102kB 8.9MB/s \n","\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q tf-models-official==2.3.0\n","from official.nlp.optimization import create_optimizer # creates AdamW optimizer used for BERT - tune?"]},{"cell_type":"markdown","metadata":{"id":"IVI_1eHjfEU0"},"source":["Define parameters for training"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":196224,"status":"ok","timestamp":1613118652544,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"KhyWdfOCPKm0"},"outputs":[],"source":["EPOCHS = 10\n","tot_train_steps = n_train * EPOCHS\n","warmup_steps = int(EPOCHS * n_train * 0.1 / global_batch_size)"]},{"cell_type":"markdown","metadata":{"id":"IdWbtCOYOWNj"},"source":["Specify checkpoint to load (for epoch > 0)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":196220,"status":"ok","timestamp":1613118652545,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"fcMkmSKUO2WM"},"outputs":[],"source":["lh_options = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")"]},{"cell_type":"markdown","metadata":{"id":"wBAnu-uxOZ2J"},"source":["Set up training functions"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":196215,"status":"ok","timestamp":1613118652545,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"JDKq0Z0_pltA"},"outputs":[],"source":["margins = [10 * 10**(x) for x in range(-3,3)]"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":196206,"status":"ok","timestamp":1613118652546,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"M4yd0zDMfnMY"},"outputs":[],"source":["def training_setup(lr, margin, load=False, batch_nr=27113):\n","\n","  with strategy.scope():\n","    encoder_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n","    encoder_model.trainable = True\n","\n","    encs, nonzero = CustomBertLayer(encoder_model)(input_ids)\n","    model = keras.Model(input_ids, [encs, nonzero])\n","    model.trainable = encoder_model.trainable\n","    loss_obj = triplet_loss(margin)\n","    optimizer = create_optimizer(lr, \n","                                 num_train_steps=tot_train_steps,\n","                                 num_warmup_steps=warmup_steps)\n","    opt_checkpoint = tf.train.Checkpoint(optimizer=optimizer)\n","    \n","    if load:\n","      latest = tf.train.latest_checkpoint(f'checkpoints_shuffle_02_10/triplet_loss_{margin}/epoch_{load}')\n","      print(f'Loading checkpoint at checkpoint/triplet_loss_{margin}/epoch_{load}...')\n","      model.load_weights(latest, options=lh_options)\n","\n","      opt_wfile = f'optimizers_shuffle_02_10/triplet_loss_{margin}/epoch_{load}/batch_{batch_nr}-of-27113.pkl'\n","      opt_weights = pkl.load(file=open(opt_wfile, 'rb'))\n","      optimizer._create_all_weights(model.trainable_variables)\n","      optimizer.set_weights(opt_weights)\n","\n","    def compute_loss(enc, nonzero):\n","      l, dp, dn, md = loss_obj(enc, nonzero)\n","      return l, dp, dn, md\n","\n","    def compute_metric(loss, margin):\n","      m = tf.cast(tf.greater(margin, loss), tf.float32)\n","      return m\n","\n","    def red_fn(x):\n","      return strategy.reduce(tf.distribute.ReduceOp.MEAN, x, axis=None)\n","\n","    @tf.function\n","    def distributed_train_step(dataset_inputs):\n","      pr_losses, pr_metrics, pr_dp, pr_dn, mds = strategy.run(train_step, \n","                                                         args=(dataset_inputs,))\n","      return red_fn(pr_losses), red_fn(pr_metrics), \\\n","             pr_dp.values, pr_dn.values, mds.values\n","\n","    @tf.function\n","    def distributed_test_step(dataset_inputs):\n","      pr_test_losses, pr_test_metrics = strategy.run(test_step, \n","                                                    args=(dataset_inputs,))\n","      return red_fn(pr_test_losses), red_fn(pr_test_metrics)\n","\n","    def train_step(inputs):\n","      with tf.GradientTape() as tape:\n","        enc, nz = model(inputs)\n","        loss, dp, dn, md = compute_loss(enc, nz)\n","        mtr = compute_metric(loss, margin)\n","      gradients = tape.gradient(loss, model.trainable_variables)\n","      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","      return loss, mtr, dp, dn, md\n","\n","    def test_step(inputs):\n","      test_enc, test_nz = model(inputs)\n","      test_loss = compute_loss(test_enc, test_nz)[0]\n","      test_mtr = compute_metric(test_loss, margin)\n","      return test_loss, test_mtr\n","\n","    return model, loss_obj, optimizer, \\\n","           distributed_train_step, distributed_test_step\n"]},{"cell_type":"markdown","metadata":{"id":"rRhx02WL59pH"},"source":["Define logging functions"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":196422,"status":"ok","timestamp":1613118652767,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"NFAnx2YhoxFD"},"outputs":[],"source":["with strategy.scope():\n","\n","  def log_weights(edir, b, model):\n","    edir.mkdir(exist_ok=True, parents=True)\n","    ckpt_path = edir /  f'batch_{b}-of-{n_train}'\n","    model.save_weights(filepath=ckpt_path, options=lh_options)\n","  \n","  def log_optimizer(edir, b, optimizer):\n","    edir.mkdir(exist_ok=True, parents=True)\n","    opt_wpath = edir / f'batch_{b}-of-{n_train}.pkl'\n","    pkl.dump(file=open(opt_wpath, 'wb'), \n","             obj=optimizer.get_weights())\n","\n","  def log_metrics(e, d, el, em, edps, edns, edas, logpath,\n","                  elt=None, emt=None, test=False):\n","    d[f'epoch_{e}']['losses'] = el\n","    d[f'epoch_{e}']['metrics'] = em\n","    if test:\n","      d[f'epoch_{e}']['test_losses'] = elt\n","      d[f'epoch_{e}']['test_metrics'] =  emt\n","    d[f'epoch_{e}']['dp'] = [float(e) for e in edps]\n","    d[f'epoch_{e}']['dn'] = [float(e) for e in edns]\n","    d[f'epoch_{e}']['da'] = [float(e) for e in edas]\n","    with open(logpath, 'w') as f:\n","      f.write(json.dumps(d))\n","    return d\n"]},{"cell_type":"markdown","metadata":{"id":"-LBmSxIdeuLq"},"source":["Define training loop"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":196418,"status":"ok","timestamp":1613118652768,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"lioTktTgfK66"},"outputs":[],"source":["def training_run(margin, dataset, dataset_val, \n","                 ckptpath, mpath, optpath, \n","                 epochs, examples, \n","                 lr=2e-5, load=False, batch_nr=27113):\n","\n","  with strategy.scope():\n","\n","    model, loss_obj, optimizer, \\\n","    distributed_train_step, distributed_test_step = training_setup(lr=lr, margin=margin, \n","                                                                   load=load, batch_nr=batch_nr)\n","    print(optimizer.iterations)\n","    ckpt_dir = Path(f'./{ckptpath}/triplet_loss_{margin}')\n","    metrics_dir = Path(f'./{mpath}/triplet_loss_{margin}')\n","    optimizer_dir = Path(f'./{optpath}/triplet_loss_{margin}')\n","    metrics_dir.mkdir(exist_ok=True, parents=True)\n","    logpath = metrics_dir / 'log.json'\n","\n","    if logpath.is_file():\n","      with open(logpath, 'r') as fh:\n","        mdict = json.load(fh)\n","    else:\n","      mdict = {}\n","\n","    for epoch in range(int(load)+1,epochs):\n","\n","      print(f'Epoch {epoch+1}/{epochs}')\n","      mdict[f'epoch_{epoch}'] = {}\n","      ckpt_epoch_dir = ckpt_dir / f'epoch_{epoch}'\n","      opt_epoch_dir = optimizer_dir / f'epoch_{epoch}'\n","      pb_i = Progbar(examples, stateful_metrics=['loss', 'correct'])\n","\n","      epoch_losses, epoch_metrics, epoch_test_losses, epoch_test_metrics = [], [], [], []\n","      epoch_dps, epoch_dns, epoch_das = [], [], [] \n","      batch = 0\n","      \n","      dataset_train = dataset.shuffle(examples)\n","      dataset_train = strategy.experimental_distribute_dataset(dataset_train)\n","\n","      for x in dataset_train:\n","        batch += 1\n","        loss, correct, dp, dn, md = distributed_train_step(x)\n","        epoch_losses.append(float(loss.numpy()))\n","        epoch_metrics.append(float(correct.numpy()))\n","        epoch_das += [d.numpy() for d in md] \n","        epoch_dps += [d.numpy() for d in dp]\n","        epoch_dns += [d.numpy() for d in dn] \n","        pb_i.add(1, values=[('loss', loss), ('correct', correct)])\n","        if batch % 100 == 0:\n","          if (batch % 5000 == 0):\n","            log_weights(ckpt_epoch_dir, batch, model)\n","            log_optimizer(opt_epoch_dir, batch, optimizer)\n","          mdict = log_metrics(epoch, mdict, \n","                              epoch_losses, epoch_metrics,\n","                              epoch_dps, epoch_dns, epoch_das, logpath)\n","\n","      avg_train_loss = tf.reduce_sum(epoch_losses) / examples\n","      avg_train_mtr = tf.reduce_sum(epoch_metrics) / examples\n","      log_weights(ckpt_epoch_dir, batch, model)\n","      log_optimizer(opt_epoch_dir, batch, optimizer)\n","\n","      for x in dataset_val:\n","        test_loss, test_correct = distributed_test_step(x)\n","        epoch_test_losses.append(float(test_loss.numpy()))\n","        epoch_test_metrics.append(float(test_correct.numpy()))\n","\n","      avg_test_loss = tf.reduce_sum(epoch_test_losses) / n_val\n","      avg_test_mtr = tf.reduce_sum(epoch_test_metrics) / n_val\n","        \n","      print(f'Margin: {margin}, '\n","            f'Epoch: {epoch}, '\n","            f'Loss: {avg_train_loss}, ' \n","            f'Metric: {avg_train_mtr} ,' \n","            f'Val loss: {avg_test_loss}, ' \n","            f'Val metric {avg_test_mtr}')\n","      \n","      mdict = log_metrics(epoch, mdict, \n","                          epoch_losses, epoch_metrics,\n","                          epoch_dps, epoch_dns, epoch_das,\n","                          logpath, \n","                          epoch_test_losses, epoch_test_metrics, \n","                          test=True)"]},{"cell_type":"markdown","metadata":{"id":"TxN4aJShexJG"},"source":["Run training loop for hyperparameter tuning with small dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"JBf94jFegTfc"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07a5929ef049472586048e4ec3f45e88","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ecea1dcd0e624a82b83daf84d97753a0","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=363423424.0, style=ProgressStyle(descri…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_projector', 'activation_13', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fd1b68036c8>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7fd1d3ce42a0> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fd1b68036c8>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7fd1d3ce42a0> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"name":"stdout","output_type":"stream","text":["WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fd1b68036c8>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7fd1d3ce42a0> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fd1d1abcc80> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fd1d1abcc80> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING: AutoGraph could not transform <function wrap at 0x7fd1d1abcc80> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","INFO:absl:using Adamw optimizer\n"]},{"name":"stdout","output_type":"stream","text":["Loading checkpoint at checkpoint/triplet_loss_1.0/epoch_3...\n","TPUMirroredVariable:{\n","  0: <tf.Variable 'iter:0' shape=() dtype=int64, numpy=108452>,\n","  1: <tf.Variable 'iter/replica_1:0' shape=() dtype=int64, numpy=108452>,\n","  2: <tf.Variable 'iter/replica_2:0' shape=() dtype=int64, numpy=108452>,\n","  3: <tf.Variable 'iter/replica_3:0' shape=() dtype=int64, numpy=108452>,\n","  4: <tf.Variable 'iter/replica_4:0' shape=() dtype=int64, numpy=108452>,\n","  5: <tf.Variable 'iter/replica_5:0' shape=() dtype=int64, numpy=108452>,\n","  6: <tf.Variable 'iter/replica_6:0' shape=() dtype=int64, numpy=108452>,\n","  7: <tf.Variable 'iter/replica_7:0' shape=() dtype=int64, numpy=108452>\n","}\n","Epoch 5/10\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"PartitionedCall:1\", shape=(25600,), dtype=int32), values=Tensor(\"clip_by_global_norm/clip_by_global_norm/_0:0\", shape=(25600, 768), dtype=float32), dense_shape=Tensor(\"PartitionedCall:2\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"]},{"name":"stdout","output_type":"stream","text":["27113/27113 [==============================] - 18295s 672ms/step - loss: 0.1983 - correct: 1.0000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"name":"stdout","output_type":"stream","text":["Margin: 1.0, Epoch: 4, Loss: 0.03669251501560211, Metric: 0.9883036017417908 ,Val loss: 1.1744158267974854, Val metric 0.7145946025848389\n","Epoch 6/10\n","27113/27113 [==============================] - 18578s 684ms/step - loss: 0.0000e+00 - correct: 1.0000\n","Margin: 1.0, Epoch: 5, Loss: 0.02303762175142765, Metric: 0.9922592639923096 ,Val loss: 1.415094017982483, Val metric 0.7140459418296814\n","Epoch 7/10\n","  132/27113 [..............................] - ETA: 5:02:31 - loss: 0.0000e+00 - correct: 1.0000"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-8754113dac1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0;34m'metrics_shuffle_02_10'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                \u001b[0;34m'optimizers_shuffle_02_10'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 10, n_train, load='3')\n\u001b[0m","\u001b[0;32m<ipython-input-26-1e34f9295148>\u001b[0m in \u001b[0;36mtraining_run\u001b[0;34m(margin, dataset, dataset_val, ckptpath, mpath, optpath, epochs, examples, lr, load, batch_nr)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mepoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mepoch_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mepoch_das\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for m in margins[2:3]:\n","  training_run(float(m), ds_train, ds_val,\n","               'checkpoints_shuffle_02_10', \n","               'metrics_shuffle_02_10', \n","               'optimizers_shuffle_02_10',\n","                10, n_train, load='3')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":39011896,"status":"aborted","timestamp":1613157468260,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"DoZNPWkElzDA"},"outputs":[],"source":["# To dos:\n","# Note: cool embedding visualizer\n","# App for live monitoring of training"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":39011894,"status":"aborted","timestamp":1613157468263,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"Qxuoh25Uncet"},"outputs":[],"source":["#def triplet_loss(margin):\n","#  def loss_fn(enc, nonzero):\n","#    \n","    # Averaging distances\n","#    n_emb = enc[:,0,:]\n","#    p_emb = enc[:,1,:]\n","#    a_emb = enc[:,2:,:]\n","#    r = tf.reduce_sum(a_emb[0,:,:]*a_emb[0,:,:], 1)\n","#    r = tf.reshape(r, [-1, 1])\n","#    D = r - 2*tf.matmul(a_emb[0,:,:], tf.transpose(a_emb[0,:,:])) + tf.transpose(r)\n","#    mdist = tf.reduce_mean(D)\n","#    p_diff = p_emb - a_emb\n","#    n_diff = n_emb - a_emb\n","#    p_mask = tf.cast(tf.reduce_all((p_diff == p_emb), -1), tf.float32)\n","#    p_mask = tf.abs(p_mask - 1.0)\n","#    d_pos = tf.reduce_sum(tf.multiply(tf.reduce_sum(tf.square(p_diff), -1), p_mask), -1) / (nonzero-2)\n","#    d_neg = tf.reduce_sum(tf.multiply(tf.reduce_sum(tf.square(n_diff), -1), p_mask), -1) / (nonzero-2)\n","#    loss_val = tf.maximum(0.0, d_pos - d_neg + margin + 0.1*d_pos )\n","    \n","#    return tf.reduce_mean(loss_val), tf.reduce_mean(d_pos), tf.reduce_mean(d_neg), mdist\n","  \n","#  return loss_fn\n","\n","\n","#loss_val = tf.maximum(0.0, tf.math.log(d_pos/(mdist + 1e-8)) - tf.math.log(d_neg + 1e-8) - tf.math.log(1 - mdist + 1e-8) )"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":39011889,"status":"aborted","timestamp":1613157468263,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"},"user_tz":-60},"id":"ClJ4JSN0UIMh"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"name":"pushshift_triplet_tpu.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4-final"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0732264a002446bfb8fc909783de4e76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07a5929ef049472586048e4ec3f45e88":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61d3ea25d55f47898b9bcda108e2ac3a","IPY_MODEL_d0af82e9f6b447938e533866dddf1300"],"layout":"IPY_MODEL_4d122b2970d34025aa6914ab2e045fd5"}},"24cdaad388c345eab651916a2e9437d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d122b2970d34025aa6914ab2e045fd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f80457f2a9841f781f93a51aa3b1731":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61d3ea25d55f47898b9bcda108e2ac3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_5f80457f2a9841f781f93a51aa3b1731","max":442,"min":0,"orientation":"horizontal","style":"IPY_MODEL_849fe88335394cc7b5481b47c11f2064","value":442}},"849fe88335394cc7b5481b47c11f2064":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"8c1e901ac0554e068aef574f23ea2dc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3156b225a164c0dae784e6d3492b393":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b51b1b2f938241518e0ff0f7f75abaac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24cdaad388c345eab651916a2e9437d4","placeholder":"​","style":"IPY_MODEL_ed13dc586cf74d969b187098289d1f47","value":" 363M/363M [00:07&lt;00:00, 48.1MB/s]"}},"c379d2d50dcd4f12840e0d8b69524af0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_0732264a002446bfb8fc909783de4e76","max":363423424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd14cd3bda404f5abc8a9f412361cbc3","value":363423424}},"d0af82e9f6b447938e533866dddf1300":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3156b225a164c0dae784e6d3492b393","placeholder":"​","style":"IPY_MODEL_f369f0c0eda9421ca4c5382165360190","value":" 442/442 [00:08&lt;00:00, 53.7B/s]"}},"ecea1dcd0e624a82b83daf84d97753a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c379d2d50dcd4f12840e0d8b69524af0","IPY_MODEL_b51b1b2f938241518e0ff0f7f75abaac"],"layout":"IPY_MODEL_8c1e901ac0554e068aef574f23ea2dc6"}},"ed13dc586cf74d969b187098289d1f47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f369f0c0eda9421ca4c5382165360190":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd14cd3bda404f5abc8a9f412361cbc3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}}}}},"nbformat":4,"nbformat_minor":0}