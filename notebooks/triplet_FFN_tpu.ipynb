{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"pushshift_triplet_FFN_tpu.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4-final"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1yVf0JAHIfQ","executionInfo":{"status":"ok","timestamp":1613056431753,"user_tz":-60,"elapsed":9449,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}},"outputId":"63be234e-4aca-408b-8f1e-6f1b360874be"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 7.0MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 44.6MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 41.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c5692fedc28820b56170af34c0f8abe3eb2cd6e66f3c8019c197856469c391c2\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z_zi0jaEG_vR","executionInfo":{"status":"ok","timestamp":1613056434822,"user_tz":-60,"elapsed":12511,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["from tensorflow import keras\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras import layers, Input\n","from transformers import TFDistilBertModel\n","import glob\n","from tensorflow.keras.utils import Progbar\n","from google.colab import drive\n","import os\n","from pathlib import Path\n","import json\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","from IPython.display import clear_output\n","import pickle as pkl"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81GoGb-sCwOj","executionInfo":{"status":"ok","timestamp":1613056451510,"user_tz":-60,"elapsed":29193,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}},"outputId":"84478873-78e4-482f-a910-ebe1dda5f3bb"},"source":["drive.mount('/content/drive/')\n","%cd 'drive/My Drive/personality_reddit'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n","/content/drive/My Drive/personality_reddit\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iO-O0tobHOpE","executionInfo":{"status":"ok","timestamp":1613056452818,"user_tz":-60,"elapsed":30496,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["from tools.datasets import load_tfrecord_triplet_nn1"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m7xIzA1Zborq"},"source":["## Initialize TPU strategy"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfdvPoLTHobI","executionInfo":{"status":"ok","timestamp":1613056467752,"user_tz":-60,"elapsed":45425,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}},"outputId":"a29384bc-5ee3-4bdc-9086-0511dced5659"},"source":["try:\n","  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n","  print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n","except ValueError:\n","  print('TPU failed to initialize.')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.96.152.106:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.96.152.106:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["Running on TPU  ['10.96.152.106:8470']\n","Number of accelerators:  8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MpMvuoq6N2UY","executionInfo":{"status":"ok","timestamp":1613056467753,"user_tz":-60,"elapsed":45421,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["AUTO = tf.data.experimental.AUTOTUNE"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IjLNbAa9G_vc"},"source":["## Load and split dataset"]},{"cell_type":"code","metadata":{"id":"anDqiMTLhYRj","executionInfo":{"status":"ok","timestamp":1613056467754,"user_tz":-60,"elapsed":45419,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["batch_size = 1 # >1 not feasible on Colab TPUs - crashes at 10Gb requirement\n","global_batch_size = batch_size * strategy.num_replicas_in_sync\n","n_posts = 50\n","samples_in_toy_dataset = 10000"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7K0T-bUN-su","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613056529906,"user_tz":-60,"elapsed":107566,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}},"outputId":"fadce8b0-e959-453a-c86e-3a099e53a6dd"},"source":["from google.colab import auth\n","auth.authenticate_user()\n","!gcloud config set project thematic-cursor-254011"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Updated property [core/project].\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EY_DK7PMDnmD","executionInfo":{"status":"ok","timestamp":1613056531300,"user_tz":-60,"elapsed":108953,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["fre = 'gs://personality_reddit/triplet_nn1/*-of-999.tfrecord'\n","fnames = tf.io.gfile.glob(fre)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"FllY1BpyG_vc","executionInfo":{"status":"ok","timestamp":1613056531732,"user_tz":-60,"elapsed":109378,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["ds_triplet = load_tfrecord_triplet_nn1(filenames=fnames,\n","                                       deterministic=False,\n","                                       num_parallel_calls=AUTO)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"VbzPrVfSJWID","executionInfo":{"status":"ok","timestamp":1613056531733,"user_tz":-60,"elapsed":109372,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["ds_triplet = ds_triplet.map(lambda x: tf.reverse(x['input_ids'], [0])[:n_posts,:])\n","ds_triplet = ds_triplet.prefetch(AUTO).padded_batch(global_batch_size, \n","                                                    padded_shapes=[n_posts, None],\n","                                                    drop_remainder=True)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z2QIJyHPIUm9"},"source":["Count number of examples / batches"]},{"cell_type":"code","metadata":{"id":"w0dfP625Hkoy","executionInfo":{"status":"ok","timestamp":1613056531735,"user_tz":-60,"elapsed":109369,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["c=38734\n","#c=0\n","#for _ in ds_triplet:\n","#  c += 1"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"0pZQLGE-PaPC","executionInfo":{"status":"ok","timestamp":1613056531970,"user_tz":-60,"elapsed":109600,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["input_ids = Input(shape=(None, 512), \n","                  dtype='int32', \n","                  name='input_ids')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8bdel8nG_vd","executionInfo":{"status":"ok","timestamp":1613056531973,"user_tz":-60,"elapsed":109600,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["n_examples = c\n","n_train = int(n_examples * .7)\n","n_val = int(n_examples * .1)\n","n_test = n_examples - (n_train + n_val)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zx-sjp7TG_vd","executionInfo":{"status":"ok","timestamp":1613056531974,"user_tz":-60,"elapsed":109598,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["ds_tuning = ds_triplet.take(2)\n","ds_train = ds_triplet.take(n_train)\n","ds_test = ds_triplet.skip(n_train + n_val)\n","ds_val = ds_triplet.skip(n_train).take(n_val)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-hsvF1XbA-6","executionInfo":{"status":"ok","timestamp":1613056531976,"user_tz":-60,"elapsed":109596,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["ds_tuning = strategy.experimental_distribute_dataset(ds_tuning)\n","#ds_train = strategy.experimental_distribute_dataset(ds_train)\n","ds_val = strategy.experimental_distribute_dataset(ds_val)\n","ds_test = strategy.experimental_distribute_dataset(ds_test)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RFVfeabcSxdx"},"source":["Define useful function"]},{"cell_type":"code","metadata":{"id":"qsxK7Ix-Sxdy","executionInfo":{"status":"ok","timestamp":1613056531976,"user_tz":-60,"elapsed":109592,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["def compute_average_distance_anchor(enc, nonzero):\n","    a_emb = enc[:,2:,]\n","    r = tf.reduce_sum(a_emb[0,:,:] * a_emb[0,:,:], 1)\n","    mask = tf.abs(tf.cast(tf.equal(r,0), tf.float32) - 1.0)\n","    r = tf.reshape(r, [-1, 1])\n","    D = r - 2*tf.matmul(a_emb[0,:,:], \n","                        tf.transpose(a_emb[0,:,:])) + tf.transpose(r)\n","    D = tf.transpose(D * mask) * mask\n","    D = tf.linalg.band_part(D,-1,0) # lower triangle\n","    nr_comb = tf.reduce_sum(tf.cast(tf.range(1,n_posts-1), tf.float32) * mask)\n","    mdist = tf.divide(tf.reduce_sum(D), nr_comb)\n","    return mdist"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7xEmMYYSxdy","executionInfo":{"status":"ok","timestamp":1613056531977,"user_tz":-60,"elapsed":109590,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["def compute_average_encoding_anchor(enc, nonzero):\n","    a_emb = tf.divide(tf.reduce_sum(enc[:,2:,:], axis=1), nonzero-2)\n","    a_emb = tf.expand_dims(a_emb, axis=0)\n","    return a_emb"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1S6L_ZwHNS1x"},"source":["## Define model"]},{"cell_type":"code","metadata":{"id":"8RbNdsX5NMbK","executionInfo":{"status":"ok","timestamp":1613056531979,"user_tz":-60,"elapsed":109589,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["class CustomBertLayer(keras.Model):\n","  def __init__(self, model, name=None, trainable=True):\n","    super(CustomBertLayer, self).__init__(name=name)\n","    self.model = model\n","    self.trainable = trainable\n","    self.output_signature = tf.float32\n","\n","  def call(self, input):\n","    def red_fn(x):\n","      enc = self.model(x).last_hidden_state[:,0,:]\n","      mask = tf.cast(tf.not_equal(tf.reduce_mean(x, axis=1), 0), \n","                     tf.float32)\n","      masked = tf.multiply(enc, tf.expand_dims(mask, 1))\n","      return masked\n","\n","    enc = tf.vectorized_map(lambda x: red_fn(x), elems=input)\n","    nonzero = tf.cast(tf.math.count_nonzero(tf.reduce_sum(input, axis=-1), axis=1), tf.float32)\n","    return enc, nonzero"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZwWpw0XSxdy","executionInfo":{"status":"ok","timestamp":1613056531980,"user_tz":-60,"elapsed":109586,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["dense_shape = 768\n","n_dense = 3"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-hajPS0cSxdy","executionInfo":{"status":"ok","timestamp":1613056531981,"user_tz":-60,"elapsed":109584,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["class FFNModel(keras.Model):\n","\n","    ''' BERT encodings are passed to feedforward layers \n","        Number and size can vary '''\n","\n","    def __init__(self, encoder_model, \n","                 dense_shape=768, \n","                 n_dense=3, \n","                 trainable=False,\n","                 dense_activation='relu', \n","                 name=None):\n","        super(FFNModel, self).__init__(name=name)\n","\n","        self.encoder = CustomBertLayer(encoder_model)\n","        self.encoder.trainable = trainable\n","        self.dense_layers = keras.Sequential([keras.layers.Dense(dense_shape, \n","                                                                 activation=dense_activation) \n","                                            for _ in range(n_dense)])\n","        self.avg_dist_lambda = layers.Lambda(lambda x: compute_average_distance_anchor(*x))\n","        self.avg_anchor_enc_lambda = layers.Lambda(lambda x: compute_average_encoding_anchor(*x))\n","        self.avg_concat = layers.Concatenate(axis=1)\n","        self.output_signature = tf.float32\n","\n","    def call(self, input):\n","        enc, nonzero = self.encoder(input)\n","        avg_anchor_dist = self.avg_dist_lambda([enc, nonzero])\n","        avg_anchor_enc = self.avg_anchor_enc_lambda([enc, nonzero])\n","        enc = self.avg_concat([enc[:,:2,:], avg_anchor_enc])\n","        enc = self.dense_layers(enc)\n","        return enc, avg_anchor_dist, nonzero"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YvNNfs-nJ5X","executionInfo":{"status":"ok","timestamp":1613056531983,"user_tz":-60,"elapsed":109580,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["def triplet_loss(margin):\n","  def loss_fn(enc):\n","    # Get embeddings\n","    n_emb = enc[:,0,:]\n","    p_emb = enc[:,1,:]\n","    a_emb = enc[:,2,:]\n","    # Compute distances\n","    d_pos = tf.reduce_sum(tf.square(a_emb - p_emb), 1)\n","    d_neg = tf.reduce_sum(tf.square(a_emb - n_emb), 1)\n","    # Compute loss\n","    loss_val = tf.maximum(0.0, margin + (d_pos - d_neg))\n","    # Return\n","    loss_val = tf.reduce_mean(loss_val)\n","    d_pos = tf.reduce_mean(d_pos)\n","    d_neg = tf.reduce_mean(d_neg)   \n","    return loss_val, d_pos, d_neg\n","  return loss_fn"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U9vU8AqjG_vd"},"source":["## Training protocol"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmV8h3BtnQMv","executionInfo":{"status":"ok","timestamp":1613056544491,"user_tz":-60,"elapsed":122085,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}},"outputId":"cb379b21-3181-4b53-9750-c3e7f323e677"},"source":["!pip install -q tf-models-official==2.3.0\n","from official.nlp.optimization import create_optimizer # creates AdamW optimizer used for BERT - tune?"],"execution_count":23,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 849kB 6.1MB/s \n","\u001b[K     |████████████████████████████████| 37.6MB 1.5MB/s \n","\u001b[K     |████████████████████████████████| 174kB 51.4MB/s \n","\u001b[K     |████████████████████████████████| 102kB 10.6MB/s \n","\u001b[K     |████████████████████████████████| 358kB 42.9MB/s \n","\u001b[K     |████████████████████████████████| 706kB 46.3MB/s \n","\u001b[K     |████████████████████████████████| 1.2MB 36.8MB/s \n","\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IVI_1eHjfEU0"},"source":["Define parameters for training"]},{"cell_type":"code","metadata":{"id":"KhyWdfOCPKm0","executionInfo":{"status":"ok","timestamp":1613056544491,"user_tz":-60,"elapsed":122082,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["EPOCHS = 10\n","tot_train_steps = n_train * EPOCHS\n","warmup_steps = int(EPOCHS * n_train * 0.1 / global_batch_size)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IdWbtCOYOWNj"},"source":["Specify checkpoint to load (for epoch > 0)"]},{"cell_type":"code","metadata":{"id":"fcMkmSKUO2WM","executionInfo":{"status":"ok","timestamp":1613056544492,"user_tz":-60,"elapsed":122078,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["lh_options = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wBAnu-uxOZ2J"},"source":["Set up training functions"]},{"cell_type":"code","metadata":{"id":"JDKq0Z0_pltA","executionInfo":{"status":"ok","timestamp":1613056544492,"user_tz":-60,"elapsed":122075,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["margins = [10 * 10**(x) for x in range(-3,3)]"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"zIoqd9sHT8FZ","executionInfo":{"status":"ok","timestamp":1613056544495,"user_tz":-60,"elapsed":122074,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["red_fn = lambda x: strategy.reduce(tf.distribute.ReduceOp.MEAN, x, axis=None)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4yd0zDMfnMY","executionInfo":{"status":"ok","timestamp":1613056544495,"user_tz":-60,"elapsed":122071,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["def training_setup(lr, margin, load=False, batch_nr=27113):\n","\n","  with strategy.scope():\n","    encoder_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n","    enc, mdist, nonzero = FFNModel(encoder_model)(input_ids)\n","    model = keras.Model(input_ids, [enc, mdist, nonzero])\n","\n","    loss_obj = triplet_loss(margin)\n","    optimizer = create_optimizer(lr, \n","                                 num_train_steps=tot_train_steps,\n","                                 num_warmup_steps=warmup_steps)\n","    opt_checkpoint = tf.train.Checkpoint(optimizer=optimizer)\n","    \n","    if load:\n","      latest = tf.train.latest_checkpoint(f'checkpoints_FFN/triplet_loss_FFN_{margin}/epoch_{load}')\n","      print(f'Loading checkpoint at checkpoint_FFN/triplet_loss_FFN_{margin}/epoch_{load}...')\n","      model.load_weights(latest, options=lh_options)\n","\n","      opt_wfile = f'optimizers_FFN/triplet_loss_FFN_{margin}/epoch_{load}/batch_{batch_nr}-of-27113.pkl'\n","      opt_weights = pkl.load(file=open(opt_wfile, 'rb'))\n","      optimizer._create_all_weights(model.trainable_variables)\n","      optimizer.set_weights(opt_weights)\n","\n","    def compute_loss(enc):\n","      l, dp, dn = loss_obj(enc)\n","      return l, dp, dn\n","\n","    def compute_metric(loss, margin):\n","      m = tf.cast(tf.greater(margin, loss), tf.float32)\n","      return m\n","\n","    def red_fn(x):\n","      return strategy.reduce(tf.distribute.ReduceOp.MEAN, x, axis=None)\n","\n","    @tf.function\n","    def distributed_train_step(dataset_inputs):\n","      pr_losses, pr_metrics, pr_dp, pr_dn, mds = strategy.run(train_step, \n","                                                         args=(dataset_inputs,))\n","      return red_fn(pr_losses), red_fn(pr_metrics), \\\n","             pr_dp.values, pr_dn.values, mds.values\n","\n","    @tf.function\n","    def distributed_test_step(dataset_inputs):\n","      pr_test_losses, pr_test_metrics = strategy.run(test_step, \n","                                                    args=(dataset_inputs,))\n","      return red_fn(pr_test_losses), red_fn(pr_test_metrics)\n","\n","    def train_step(inputs):\n","      with tf.GradientTape() as tape:\n","        enc, md, nz = model(inputs)\n","        loss, dp, dn = compute_loss(enc)\n","        mtr = compute_metric(loss, margin)\n","      gradients = tape.gradient(loss, model.trainable_variables)\n","      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","      return loss, mtr, dp, dn, md\n","\n","    def test_step(inputs):\n","      test_enc, md, test_nz = model(inputs)\n","      test_loss = compute_loss(test_enc)[0]\n","      test_mtr = compute_metric(test_loss, margin)\n","      return test_loss, test_mtr\n","\n","    return model, loss_obj, optimizer, \\\n","           distributed_train_step, distributed_test_step\n"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rRhx02WL59pH"},"source":["Define logging functions"]},{"cell_type":"code","metadata":{"id":"NFAnx2YhoxFD","executionInfo":{"status":"ok","timestamp":1613056544495,"user_tz":-60,"elapsed":122067,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["with strategy.scope():\n","\n","  def log_weights(edir, b, model):\n","    edir.mkdir(exist_ok=True, parents=True)\n","    ckpt_path = edir /  f'batch_{b}-of-{n_train}'\n","    model.save_weights(filepath=ckpt_path, options=lh_options)\n","  \n","  def log_optimizer(edir, b, optimizer):\n","    edir.mkdir(exist_ok=True, parents=True)\n","    opt_wpath = edir / f'batch_{b}-of-{n_train}.pkl'\n","    pkl.dump(file=open(opt_wpath, 'wb'), \n","             obj=optimizer.get_weights())\n","\n","  def log_metrics(e, d, el, em, edps, edns, edas, logpath,\n","                  elt=None, emt=None, test=False):\n","    d[f'epoch_{e}']['losses'] = el\n","    d[f'epoch_{e}']['metrics'] = em\n","    if test:\n","      d[f'epoch_{e}']['test_losses'] = elt\n","      d[f'epoch_{e}']['test_metrics'] =  emt\n","    d[f'epoch_{e}']['dp'] = [float(e) for e in edps]\n","    d[f'epoch_{e}']['dn'] = [float(e) for e in edns]\n","    d[f'epoch_{e}']['da'] = [float(e) for e in edas]\n","    with open(logpath, 'w') as f:\n","      f.write(json.dumps(d))\n","    return d\n"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-LBmSxIdeuLq"},"source":["Define training loop"]},{"cell_type":"code","metadata":{"id":"lioTktTgfK66","executionInfo":{"status":"ok","timestamp":1613056544731,"user_tz":-60,"elapsed":122299,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"12439142997412364274"}}},"source":["def training_run(margin, dataset, dataset_val, \n","                 ckptpath, mpath, optpath, \n","                 epochs, examples, \n","                 lr=2e-5, load=False, batch_nr=27113):\n","\n","  with strategy.scope():\n","\n","    model, loss_obj, optimizer, \\\n","    distributed_train_step, distributed_test_step = training_setup(lr=lr, margin=margin, \n","                                                                   load=load, batch_nr=batch_nr)\n","    print(optimizer.iterations)\n","    ckpt_dir = Path(f'./{ckptpath}/triplet_loss_FFN_{margin}')\n","    metrics_dir = Path(f'./{mpath}/triplet_loss_FFN_{margin}')\n","    optimizer_dir = Path(f'./{optpath}/triplet_loss_FFN_{margin}')\n","    metrics_dir.mkdir(exist_ok=True, parents=True)\n","    logpath = metrics_dir / 'log.json'\n","\n","    if logpath.is_file():\n","      with open(logpath, 'r') as fh:\n","        mdict = json.load(fh)\n","    else:\n","      mdict = {}\n","\n","    for epoch in range(int(load)+1,epochs):\n","\n","      print(f'Epoch {epoch+1}/{epochs}')\n","      mdict[f'epoch_{epoch}'] = {}\n","      ckpt_epoch_dir = ckpt_dir / f'epoch_{epoch}'\n","      opt_epoch_dir = optimizer_dir / f'epoch_{epoch}'\n","      pb_i = Progbar(examples, stateful_metrics=['loss', 'correct'])\n","\n","      epoch_losses, epoch_metrics, epoch_test_losses, epoch_test_metrics = [], [], [], []\n","      epoch_dps, epoch_dns, epoch_das = [], [], [] \n","      batch = 0\n","\n","      dataset_train = dataset.shuffle(examples)\n","      dataset_train = strategy.experimental_distribute_dataset(dataset_train)\n","\n","      for x in dataset_train:\n","        batch += 1\n","        loss, correct, dp, dn, md = distributed_train_step(x)\n","        epoch_losses.append(float(loss.numpy()))\n","        epoch_metrics.append(float(correct.numpy()))\n","        epoch_das += [d.numpy() for d in md] \n","        epoch_dps += [d.numpy() for d in dp]\n","        epoch_dns += [d.numpy() for d in dn] \n","        pb_i.add(1, values=[('loss', loss), ('correct', correct)])\n","        if batch % 100 == 0:\n","          if (batch % 5000 == 0):\n","            log_weights(ckpt_epoch_dir, batch, model)\n","            log_optimizer(opt_epoch_dir, batch, optimizer)\n","          mdict = log_metrics(epoch, mdict, \n","                              epoch_losses, epoch_metrics,\n","                              epoch_dps, epoch_dns, epoch_das, logpath)\n","\n","      avg_train_loss = tf.reduce_sum(epoch_losses) / examples\n","      avg_train_mtr = tf.reduce_sum(epoch_metrics) / examples\n","      log_weights(ckpt_epoch_dir, batch, model)\n","      log_optimizer(opt_epoch_dir, batch, optimizer)\n","\n","      for x in dataset_val:\n","        test_loss, test_correct = distributed_test_step(x)\n","        epoch_test_losses.append(float(test_loss.numpy()))\n","        epoch_test_metrics.append(float(test_correct.numpy()))\n","\n","      avg_test_loss = tf.reduce_sum(epoch_test_losses) / n_val\n","      avg_test_mtr = tf.reduce_sum(epoch_test_metrics) / n_val\n","        \n","      print(f'Margin: {margin}, '\n","            f'Epoch: {epoch}, '\n","            f'Loss: {avg_train_loss}, ' \n","            f'Metric: {avg_train_mtr} ,' \n","            f'Val loss: {avg_test_loss}, ' \n","            f'Val metric {avg_test_mtr}')\n","      \n","      mdict = log_metrics(epoch, mdict, \n","                          epoch_losses, epoch_metrics,\n","                          epoch_dps, epoch_dns, epoch_das,\n","                          logpath, \n","                          epoch_test_losses, epoch_test_metrics, \n","                          test=True)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TxN4aJShexJG"},"source":["Run training loop for hyperparameter tuning with small dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBf94jFegTfc","outputId":"343bccd0-d455-4e8b-8d83-dfcacbee6066"},"source":["for m in margins[2:3]:\n","  training_run(float(m), ds_train, ds_val,\n","               'checkpoints_FFN', 'metrics_FFN', 'optimizers_FFN',\n","                10, n_train, load='3')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_layer_norm', 'vocab_projector', 'vocab_transform']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","INFO:absl:using Adamw optimizer\n"],"name":"stderr"},{"output_type":"stream","text":["Loading checkpoint at checkpoint_FFN/triplet_loss_FFN_1.0/epoch_3...\n","TPUMirroredVariable:{\n","  0: <tf.Variable 'iter:0' shape=() dtype=int64, numpy=108452>,\n","  1: <tf.Variable 'iter/replica_1:0' shape=() dtype=int64, numpy=108452>,\n","  2: <tf.Variable 'iter/replica_2:0' shape=() dtype=int64, numpy=108452>,\n","  3: <tf.Variable 'iter/replica_3:0' shape=() dtype=int64, numpy=108452>,\n","  4: <tf.Variable 'iter/replica_4:0' shape=() dtype=int64, numpy=108452>,\n","  5: <tf.Variable 'iter/replica_5:0' shape=() dtype=int64, numpy=108452>,\n","  6: <tf.Variable 'iter/replica_6:0' shape=() dtype=int64, numpy=108452>,\n","  7: <tf.Variable 'iter/replica_7:0' shape=() dtype=int64, numpy=108452>\n","}\n","Epoch 5/10\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["27113/27113 [==============================] - 7955s 292ms/step - loss: 0.6234 - correct: 0.7500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Margin: 1.0, Epoch: 4, Loss: 0.7730779647827148, Metric: 0.6482914090156555 ,Val loss: 0.8015159964561462, Val metric 0.6322618126869202\n","Epoch 6/10\n","27113/27113 [==============================] - 8147s 300ms/step - loss: 0.5811 - correct: 0.7500\n","Margin: 1.0, Epoch: 5, Loss: 0.7608665823936462, Metric: 0.6543862819671631 ,Val loss: 0.7975232005119324, Val metric 0.6318099498748779\n","Epoch 7/10\n","23132/27113 [========================>.....] - ETA: 20:25 - loss: 0.6931 - correct: 0.6250"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PVExIk-Bqtkx"},"source":[""],"execution_count":null,"outputs":[]}]}