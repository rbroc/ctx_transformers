{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"colab":{"name":"subreddit_pushshift_triplet_tpu.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1yVf0JAHIfQ","executionInfo":{"status":"ok","timestamp":1609940983541,"user_tz":-60,"elapsed":4369,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"d9847244-d6b3-4e66-985e-d733ec8d20fd"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GB_lpex5-j25","executionInfo":{"status":"ok","timestamp":1609941469628,"user_tz":-60,"elapsed":737,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["# CURRENT ISSUE:\n","# TPU sets loss to NAN for some examples, which is not the case for CPU (what about GPU?)\n","# Apparently, this may be related to TPU not working properly without batch dimensions or \n","# for small batches\n","\n","# PLAN:\n","# Switch to GPU if possible, otherwise run (*very* slow) on CPU\n","# Ask someone to look at code?\n","# Maybe average losses across batches\n","\n","# URGENT TO DO:\n","# Check that it trains properly\n","\n","# MINOR ISSUES IN CURRENT IMPLEMENTATION:\n","# Pad to maximum and subset to make training faster and avoid retracing?\n","# Add batching (i.e. update loss every n examples)\n","# Check metrics\n","# Implement validation\n","# Add checkpoints\n","# Add baseline bag of words model\n","# Try model2?\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z_zi0jaEG_vR","executionInfo":{"status":"ok","timestamp":1609940986502,"user_tz":-60,"elapsed":7323,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["from tensorflow import keras\n","import tensorflow as tf\n","import numpy as np\n","import keras.backend as K\n","from tensorflow.keras import layers, Input\n","from transformers import TFDistilBertModel\n","import glob\n","from tqdm import tqdm\n","from tensorflow.keras.utils import Progbar\n","from google.colab import drive\n","import os"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81GoGb-sCwOj","executionInfo":{"status":"ok","timestamp":1609940986503,"user_tz":-60,"elapsed":7315,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"28367562-6293-40f8-d027-dd96550826cd"},"source":["drive.mount('/content/drive/')\n","%cd 'drive/My Drive/personality_reddit'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/My Drive/personality_reddit\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iO-O0tobHOpE","executionInfo":{"status":"ok","timestamp":1609940986505,"user_tz":-60,"elapsed":5139,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["from tools.datasets import load_tfrecord_triplet_nn1"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfdvPoLTHobI","executionInfo":{"status":"ok","timestamp":1609940996139,"user_tz":-60,"elapsed":14613,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"4e911ba7-6dee-48a3-df7d-6a683b9262ac"},"source":["try:\n","  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n","  print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n","except ValueError:\n","  print('TPU failed to initialize.')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.78.63.114:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.78.63.114:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["Running on TPU  ['10.78.63.114:8470']\n","Number of accelerators:  8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TUhdmxkEG_vY","executionInfo":{"status":"ok","timestamp":1609941000150,"user_tz":-60,"elapsed":17022,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"cd91d710-ad95-4834-b054-a5e00427f94e"},"source":["encoder_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"x1GWmBBZdqzJ"},"source":["## Set hyperparameters"]},{"cell_type":"code","metadata":{"id":"p7qYy4Zwdp3X","executionInfo":{"status":"ok","timestamp":1609941000151,"user_tz":-60,"elapsed":16400,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["loss_margin = .5\n","batch_size = 16\n","learning_rate = 10e-5\n","dense_shape = 128 # FFN\n","n_dense = 3 # FFN"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AgkM9sN2XjFQ"},"source":["## Define triplet loss"]},{"cell_type":"code","metadata":{"id":"Za6UPwh_G_vZ","executionInfo":{"status":"ok","timestamp":1609941000152,"user_tz":-60,"elapsed":15569,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["class TripletLoss(keras.losses.Loss):\n","\n","    ''' Compute triplet loss for Bert encodings'''\n","\n","    def __init__(self, margin=0, raw_enc=True):\n","        super().__init__()\n","        self.margin = margin\n","        self.raw_enc = raw_enc\n","    \n","    def call(self, y_true, y_pred):\n","      \n","        if self.raw_enc:\n","            a_emb = tf.reduce_mean(y_pred.last_hidden_state[:, :-2, :], axis=1)\n","            p_emb = y_pred.last_hidden_state[:, -2, :]\n","            n_emb = y_pred.last_hidden_state[:, -1, :]\n","        else:\n","            a_emb = y_pred[0]\n","            p_emb = y_pred[1]\n","            n_emb = y_pred[2]\n","        \n","        d_pos = tf.reduce_sum(tf.square(a_emb - p_emb), 1)\n","        d_neg = tf.reduce_sum(tf.square(a_emb - n_emb), 1)\n","        loss_val = tf.maximum(0.0, self.margin + d_pos - d_neg)\n","        loss_val = tf.reduce_mean(loss_val)\n","        return loss_val"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"13EupIbRG_vZ","executionInfo":{"status":"ok","timestamp":1609941000152,"user_tz":-60,"elapsed":15167,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["class TripletAccuracy(tf.keras.metrics.Metric):\n","      \n","    ''' Metric tracking whether model assigns lower distance to\n","        positive example '''\n","    \n","    def __init__(self, name='accuracy', margin=.5, **kwargs):\n","        super(TripletAccuracy, self).__init__(name=name, **kwargs)\n","        self.correct = tf.Variable(0, dtype=tf.float32)\n","        self.margin = tf.constant(margin, dtype=tf.float32)\n","        \n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        corr = tf.cast(tf.math.greater(self.margin, y_pred), tf.float32)\n","        self.correct.assign(tf.reduce_mean(corr))\n","\n","    def result(self):\n","        return self.correct\n","\n","    def reset_states(self):\n","        self.correct.assign(0.)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BjP8wLoAG_va"},"source":["## NNet 1"]},{"cell_type":"code","metadata":{"id":"M6G3uyGxIH9g","executionInfo":{"status":"ok","timestamp":1609941000153,"user_tz":-60,"elapsed":13703,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["AUTO = tf.data.experimental.AUTOTUNE"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qqFXfunG_va","executionInfo":{"status":"ok","timestamp":1609940425230,"user_tz":-60,"elapsed":25855,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"19a46480-3bd8-4616-c180-8de1412c7248"},"source":["input_ids = Input(shape=(512), dtype='int32', name='input_ids')\n","encoder_model.trainable = True\n","encodings_trainable = encoder_model(input_ids)\n","encoder_model.trainable = False\n","encodings_frozen = encoder_model(input_ids)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f1fb472a660>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f1fcbf72e58> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f1fb472a660>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7f1fcbf72e58> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f1fc99058c8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: AutoGraph could not transform <function wrap at 0x7f1fc99058c8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181},"id":"sAX2rrbJG_va","executionInfo":{"status":"error","timestamp":1609940425230,"user_tz":-60,"elapsed":19598,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"d451c5d7-83f4-48e4-ba39-b6cd3741823d"},"source":["model1.trainable = True\n","model1.summary()"],"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-a86dfb1d7a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"IN87JSuoG_vb"},"source":["## NNet 2"]},{"cell_type":"code","metadata":{"id":"laVLtYHkG_vb","executionInfo":{"status":"ok","timestamp":1609936167493,"user_tz":-60,"elapsed":34095,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["class FFNModel(keras.Model):\n","\n","    ''' BERT encodings are passed to feedforward layers \n","        Number and size can vary '''\n","\n","    def __init__(self, encoder, \n","                dense_shape=128, n_dense=3, \n","                trainable=False,\n","                dense_act='relu', name=None):\n","        super(FFNModel, self).__init__(name=name)\n","\n","        self.encoder = encoder\n","        self.encoder.trainable = trainable\n","        self.dense_layers = keras.Sequential([keras.layers.Dense(dense_shape, \n","                                                                 activation=dense_act) \n","                                            for _ in range(n_dense)])\n","        self.output_signature = tf.float32\n","\n","    def call(self, input):\n","        enc = self.encoder(input)\n","        x_p = self.dense_layers(enc.last_hidden_state[:,-2,:])\n","        x_n = self.dense_layers(enc.last_hidden_state[:,-1,:])\n","        x_a = keras.backend.mean(enc.last_hidden_state[:,:-2,:], axis=1)\n","        x_a = self.dense_layers(x_a)\n","        return x_a, x_p, x_n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hlV5PNQqG_vc","executionInfo":{"status":"ok","timestamp":1609936168512,"user_tz":-60,"elapsed":34718,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"d4dcb4c2-5fa4-4353-fc1d-3463ee0c0146"},"source":["ffn_out = FFNModel(encoder_model, dense_shape=dense_shape, n_dense=n_dense)(input_ids)\n","model2 = keras.Model(input_ids, ffn_out)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8JufnxING_vc","executionInfo":{"status":"ok","timestamp":1609936168513,"user_tz":-60,"elapsed":34542,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"b04b8806-1980-45c4-9a18-8c8f7c5bc0b1"},"source":["model2.summary()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_ids (InputLayer)       [(None, 512)]             0         \n","_________________________________________________________________\n","ffn_model (FFNModel)         ((None, 128), (None, 128) 66494336  \n","=================================================================\n","Total params: 66,494,336\n","Trainable params: 131,456\n","Non-trainable params: 66,362,880\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IjLNbAa9G_vc"},"source":["## Load and split dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7K0T-bUN-su","executionInfo":{"status":"ok","timestamp":1609941034823,"user_tz":-60,"elapsed":40557,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"336f254e-72a5-46da-f8c0-f0bf782696bd"},"source":["from google.colab import auth\n","auth.authenticate_user()\n","!gcloud config set project thematic-cursor-254011"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Updated property [core/project].\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EY_DK7PMDnmD","executionInfo":{"status":"ok","timestamp":1609941036450,"user_tz":-60,"elapsed":42019,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["fre = 'gs://personality_reddit/triplet_nn1/*-of-999.tfrecord'\n","fnames = tf.io.gfile.glob(fre)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"FllY1BpyG_vc","executionInfo":{"status":"ok","timestamp":1609941036451,"user_tz":-60,"elapsed":41636,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["ds_triplet = load_tfrecord_triplet_nn1(filenames=fnames,\n","                                       deterministic=False,\n","                                       num_parallel_calls=AUTO)\n","ds_triplet = ds_triplet.prefetch(AUTO) # Map"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8bdel8nG_vd","executionInfo":{"status":"ok","timestamp":1609941036451,"user_tz":-60,"elapsed":41074,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["n_examples = 167320\n","n_train = int(167320 * .7)\n","n_val = int(167320 * .1)\n","n_test = 167320 - (n_train + n_val)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zx-sjp7TG_vd","executionInfo":{"status":"ok","timestamp":1609941036451,"user_tz":-60,"elapsed":39275,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["#ds_triplet = ds_triplet.shuffle(100, seed=0)\n","#ds_triplet = ds_triplet.map(lambda x: x['input_ids'][:2,:])\n","ds_train = ds_triplet.take(n_train)\n","ds_test = ds_triplet.skip(n_train + n_val)\n","ds_val = ds_triplet.skip(n_train).take(n_val)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-hsvF1XbA-6","executionInfo":{"status":"ok","timestamp":1609941036454,"user_tz":-60,"elapsed":39119,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["ds_train = strategy.experimental_distribute_dataset(ds_train)\n","ds_val = strategy.experimental_distribute_dataset(ds_val)\n","ds_test = strategy.experimental_distribute_dataset(ds_test)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U9vU8AqjG_vd"},"source":["## Training protocol"]},{"cell_type":"code","metadata":{"id":"v7FvTq-zG_vd","executionInfo":{"status":"ok","timestamp":1609939750718,"user_tz":-60,"elapsed":461,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["metric = TripletAccuracy(margin=.5)\n","loss_model1 = TripletLoss(margin=.5, raw_enc=True)\n","loss_model2 = TripletLoss(margin=.5, raw_enc=False)\n","optimizer = keras.optimizers.Adam(learning_rate=10e-5)\n","#model2 = keras.Model(input_ids, ffn_out)"],"execution_count":138,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4yd0zDMfnMY","executionInfo":{"status":"ok","timestamp":1609941049711,"user_tz":-60,"elapsed":703,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}}},"source":["with strategy.scope():\n","\n","  model = keras.Model(input_ids, encodings_trainable)\n","  metric_obj = TripletAccuracy(margin=loss_margin)\n","  loss_obj = TripletLoss(margin=loss_margin, raw_enc=True)\n","  loss_obj.reduction = tf.keras.losses.Reduction.NONE\n","  optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n","\n","  def compute_loss(enc):\n","    l = loss_obj(y_true=None, y_pred=enc)\n","    return tf.math.divide(l, strategy.num_replicas_in_sync)\n","  \n","  @tf.function\n","  def distributed_train_step(dataset_inputs):\n","    pr_losses, pr_metrics = strategy.run(train_step, args=(dataset_inputs,))\n","    red_fn = lambda x: strategy.reduce(tf.distribute.ReduceOp.SUM, x, axis=None)\n","    return red_fn(pr_losses), red_fn(pr_metrics)\n","\n","  def train_step(inputs):\n","    with tf.GradientTape() as tape:\n","      enc = model(inputs)\n","      loss = compute_loss(enc)\n","    \n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    metric_obj.update_state(y_true=None, y_pred=loss)\n","    return loss, metric_obj.result()"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":854},"id":"0iKxPsEI98K6","executionInfo":{"status":"error","timestamp":1609941237674,"user_tz":-60,"elapsed":2464,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"9de230da-64f2-42f5-eba2-e2c6e9ff4e8b"},"source":["EPOCHS = 1\n","\n","with strategy.scope():\n","  for epoch in range(EPOCHS):\n","\n","    pb_i = Progbar(n_train, stateful_metrics=['loss', 'correct'])\n","    tf.print(f'Epoch {int(epoch)}')\n","\n","    epoch_losses = []\n","    epoch_metrics = []\n","    num_batches = 0\n","\n","    for x in ds_train:\n","      loss, correct = distributed_train_step(x)\n","      epoch_losses.append(loss)\n","      epoch_metrics.append(correct)\n","      num_batches += 1\n","\n","      pb_i.add(1, values=[('loss', loss), ('correct', int(correct))])\n","\n","    metric_obj.reset_states()  "],"execution_count":22,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, None, 512) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 512), dtype=tf.int32, name='input_ids'), name='input_ids', description=\"created by layer 'input_ids'\"), but it was called on an input with incompatible shape (None, 512).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, None, 512) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 512), dtype=tf.int32, name='input_ids'), name='input_ids', description=\"created by layer 'input_ids'\"), but it was called on an input with incompatible shape (None, 512).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, None, 512) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 512), dtype=tf.int32, name='attention_mask'), name='attention_mask', description=\"created by layer 'attention_mask'\"), but it was called on an input with incompatible shape (None, 512).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, None, 512) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 512), dtype=tf.int32, name='attention_mask'), name='attention_mask', description=\"created by layer 'attention_mask'\"), but it was called on an input with incompatible shape (None, 512).\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"error","ename":"StagingError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-f0d020900c38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mepoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mepoch_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    <ipython-input-19-3c5521ea96f2>:17 distributed_train_step  *\n        pr_losses, pr_metrics = strategy.run(train_step, args=(dataset_inputs,))\n    <ipython-input-19-3c5521ea96f2>:23 train_step  *\n        enc = model(inputs)\n    <ipython-input-11-3c9d098fcd00>:9 call  *\n        enc = tf.map_fn(lambda x: self.model({'input_ids': x[0],\n    /usr/local/lib/python3.6/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py:606 call  *\n        outputs = self.distilbert(\n    /usr/local/lib/python3.6/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py:461 call  *\n        embedding_output = self.embeddings(\n    /usr/local/lib/python3.6/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py:118 call  *\n        return self._embedding(input_ids, position_ids, inputs_embeds, training=training)\n    /usr/local/lib/python3.6/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py:135 _embedding  *\n        seq_length = shape_list(input_ids)[1]\n\n    IndexError: list index out of range\n"]}]},{"cell_type":"markdown","metadata":{"id":"oTQTDad6_FY2"},"source":["### Legacy code snippets"]},{"cell_type":"code","metadata":{"id":"1UYwICxnewNO"},"source":["  #@tf.function\n","  #def distributed_test_step(dataset_inputs):\n","  #  strategy.run(test_step, args=(dataset_inputs,))\n","  #def test_step(inputs):\n","  #  images, labels = inputs\n","  #\n","  #  predictions = model(images)\n","  #  loss = loss_object(labels, predictions)\n","  #\n","  #  test_loss.update_state(loss)\n","  #  test_accuracy.update_state(labels, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OarHJ262G_vd"},"source":["#def forward_step(x, model, loss_obj):\n","#    enc = model(x)\n","#    loss = loss_obj(y_true=None, y_pred=enc)\n","#    return enc, loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0tfRrP4EooDi"},"source":["    # TESTING LOOP\n","    #for x in get_validation_dataset():\n","    #  distributed_test_step(x)\n","\n","    #template = (\"Epoch {}, Loss: {:.2f}, Accuracy: {:.2f}, Test Loss: {:.2f}, \"\n","    #            \"Test Accuracy: {:.2f}\")\n","    #print (template.format(epoch+1, train_loss,\n","    #                       train_accuracy.result()*100, test_loss.result() / strategy.num_replicas_in_sync,\n","    #                       test_accuracy.result()*100))\n","\n","    #test_loss.reset_states()\n","    #rain_accuracy.reset_states()\n","    #test_accuracy.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fRckGoCCG_ve"},"source":["# Possibly change batch loop into more efficient map function?\n","def run_epoch(opt, model, loss_obj, metric_obj, \n","              training_data, n_examples, forward_only):\n","    ''' Run single training epoch and return list of losses and metrics'''\n","    batch_losses, batch_metrics = [], []\n","    losses, metrics = [], []\n","    c = 0\n","    pb_i = Progbar(n_examples, stateful_metrics=['loss', 'correct'])\n","\n","    # Also edit this (should also be according to batch size)\n","    if forward_only is True:\n","      pb_i = Progbar(n_examples, stateful_metrics=['loss', 'correct'])\n","      for x in training_data:\n","        enc, loss = forward_step(x, model, loss_obj)\n","        losses.append(loss)\n","        metric_obj.update_state(y_true=None, y_pred=loss)\n","        metrics.append(metric_obj.result())\n","        pb_i.add(1, values=[('loss', loss), ('correct', int(metric_obj.result()))])\n","    \n","    # \n","    else:\n","      pb_i = Progbar(int(n_examples/batch_size), \n","                     stateful_metrics=['loss', 'correct'])\n","      for x in training_data:\n","        c += 1\n","        if c % batch_size != 0:\n","          enc, loss = forward_step(x, model, loss_obj)\n","          batch_losses.append(loss)\n","          metric_obj.update_state(y_true=None, y_pred=loss)\n","          batch_metrics.append(metric_obj.result())\n","        else:\n","\n","          with tf.GradientTape() as tape:\n","              enc, loss = forward_step(x, model, loss_obj)\n","              batch_losses.append(loss)\n","              batch_loss = tf.math.reduce_mean(batch_losses)\n","              gradients = tape.gradient(batch_loss, model.trainable_weights)\n","              opt.apply_gradients(zip(gradients, model.trainable_weights))\n","              metric_obj.update_state(y_true=None, y_pred=loss)\n","              batch_metrics.append(metric_obj.result())\n","              batch_metric = tf.math.reduce_mean(batch_metrics)\n","\n","          losses.append(batch_loss)\n","          batch_losses = []\n","          metrics.append(batch_metric)\n","          batch_metrics = []\n","          pb_i.add(1, values=[('loss', batch_loss), ('correct', int(batch_metric))])\n","    return losses, metrics"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3VcL0xHxG_ve"},"source":["Define general training function"]},{"cell_type":"code","metadata":{"id":"9dEnAIMUG_ve"},"source":["def run_training(n_epochs, \n","                 optimizer, model, \n","                 loss_fn, metric_obj,\n","                 training_data, \n","                 n_examples,\n","                 forward_only=False):\n","    ''' Run full training loop \n","    Args:\n","        n_epochs (int): number of epochs to train\n","        optimizer (keras.optimizers or str): optimizer\n","        model (keras.Model): model ot train\n","        loss_fn (keras.losses.Loss, function or str): loss function\n","        training_data (TFDataset): dataset to train on \n","        forward_only (bool): if True, does not update gradients\n","    '''\n","    for epoch in range(n_epochs):\n","        tf.print(f'Epoch {int(epoch)}')\n","        losses_train, metrics_train = run_epoch(optimizer, model, \n","                                                loss_fn, metric_obj,\n","                                                training_data, \n","                                                n_examples,\n","                                                forward_only)\n","        metric_obj.reset_states()\n","    return losses_train, metrics_train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KigWu6fcG_vf"},"source":["Train FNN "]},{"cell_type":"code","metadata":{"id":"AyV1tZGao1Ln"},"source":["losses_nn1_nt, metric_nn1_nt = run_training(n_epochs=1, \n","                                            optimizer=optimizer, \n","                                            model=model1, \n","                                            loss_fn=loss_model1, \n","                                            metric_obj=metric,\n","                                            training_data=ds_train.take(1600),\n","                                            n_examples=1600,\n","                                            forward_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NUko9OHKXD26"},"source":["import seaborn as sns\n","from matplotlib import pyplot as plt\n","sns.scatterplot(x=range(len(losses_nn1_nt)), y=[l.numpy() for l in losses_nn1_nt])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HgiF2DfCoLIZ"},"source":["import seaborn as sns\n","from matplotlib import pyplot as plt\n","sns.scatterplot(x=range(len(metric_nn1_nt)), y=[l.numpy() for l in metric_nn1_nt])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"edoqjzrBG_vf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609867567869,"user_tz":-60,"elapsed":148072,"user":{"displayName":"Roberta Rocca","photoUrl":"","userId":"01470378711455560073"}},"outputId":"176938b4-c4d2-41c1-8408-883ab5cf82de"},"source":["losses_nn1, metrics_nn1 = run_training(n_epochs=1, \n","                                      optimizer=optimizer, \n","                                      model=model1, \n","                                      loss_fn=loss_model1, \n","                                      metric_obj=metric,\n","                                      training_data=ds_train.take(10),\n","                                      n_examples=10,\n","                                      forward_only=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['attention_mask'] which did not match any model input. They will be ignored by the model.\n","  [n for n in tensors.keys() if n not in ref_input_names])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"uS2Q-Fx-orMt"},"source":["import seaborn as sns\n","from matplotlib import pyplot as plt\n","sns.scatterplot(x=range(len(losses_nn1)), y=[l.numpy() for l in losses_nn1])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gD7QmN--ottt"},"source":["import seaborn as sns\n","from matplotlib import pyplot as plt\n","sns.scatterplot(x=range(len(metrics_nn1)), y=[l.numpy() for l in metrics_nn1])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IvkgyuyiommN"},"source":["losses_nn2, metric_nn2 = run_training(n_epochs=1, \n","                                      optimizer=optimizer, \n","                                      model=model2, \n","                                      loss_fn=loss_model2, \n","                                      metric_obj=metric,\n","                                      training_data=ds_train.take(10), \n","                                      n_examples=10)\n","# Fix:     \n","# /Users/rr48396/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:702 invalid_creator_scope\n","# \"tf.function-decorated function tried to create \"\n","# ValueError: tf.function-decorated function tried to create variables on non-first call."],"execution_count":null,"outputs":[]}]}